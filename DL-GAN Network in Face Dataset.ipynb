{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhay43/ML_Code/blob/master/DL-GAN%20Network%20in%20Face%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRQqVYYxE3jZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, Conv2DTranspose, BatchNormalization, Flatten,Reshape\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import initializers\n",
        "import tensorflow.keras as kr\n",
        "import tensorflow as tf\n",
        "import imageio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import expand_dims\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy import vstack\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN5o9wZQJoOL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "1caf3e03-d715-40c9-9e39-6a3fa2d904f0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p49DcGLoLixW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "78a8661c-b120-43d5-c581-a41e9e251539"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = '/content/drive/My Drive/Faltu/28577_36420_compressed_fer2013.csv.zip'\n",
        "with ZipFile(file_name, 'r') as zip: \n",
        "    # printing all the contents of the zip file \n",
        "    zip.printdir() \n",
        "  \n",
        "    # extracting all the files \n",
        "    print('Extracting all the files now...') \n",
        "    zip.extractall() \n",
        "    print('Done!')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File Name                                             Modified             Size\n",
            "fer2013.csv                                    2019-10-01 04:15:22    301072766\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Q9sVNkJpEG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_real_samples():\n",
        "  data = pd.read_csv('/content/fer2013.csv')\n",
        "  pixels = list()\n",
        "  pixel = list()\n",
        "  for index,row in data.iterrows():\n",
        "    pixel.append(list(map(int, (row['pixels'].split(' ')))) )\n",
        "  for i in pixel:\n",
        "    temp = list()\n",
        "    for j in i:\n",
        "      temp.append((j - 127.5) / 125.7)\n",
        "    pixels.append(temp)\n",
        "  pixel=()\n",
        "  return np.array(pixels).reshape(len(pixels), 2304)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoZNzGhnLKvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_real_samples()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCFo2j8BkMK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "def647e0-49df-4ae8-9b87-b731bf3a8f16"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35887, 2304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwrsiBehM46p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_generator(latent_dim):\n",
        "  model = Sequential()\n",
        "  # foundation for 4x4 image\n",
        "  n_nodes = 256 * 6 * 6\n",
        "  model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Reshape((6, 6, 256)))\n",
        "  # upsample to 12x12\n",
        "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  # upsample to 16x16\n",
        "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  # upsample to 32x32\n",
        "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  # output layer\n",
        "  model.add(Conv2D(1, (3,3), activation='tanh', padding='same'))\n",
        "  model.summary()\n",
        "  return model\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kI82Lh2sOjsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_discriminator(in_shape=(48,48,1)):\n",
        "  model = Sequential()\n",
        "  # normal\n",
        "  model.add(Conv2D(64, (3,3), padding='same', input_shape=in_shape))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  # downsample\n",
        "  model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  # downsample\n",
        "  model.add(Conv2D(128, (3,3), strides=(2,2), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  # downsample\n",
        "  model.add(Conv2D(256, (3,3), strides=(2,2), padding='same'))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  # classifier\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  # compile model\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ApRdGk5Olzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_real_samples(dataset, n_samples):\n",
        "  ix = np.random.randint(0, dataset.shape[0], n_samples)\n",
        "  # retrieve selected images\n",
        "  X = dataset[ix]\n",
        "  X = X.reshape((n_samples, 48, 48, 1))\n",
        "  # generate 'real' class labels (1)\n",
        "  y = ones((n_samples, 1))\n",
        "  return X, y\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rx157wl7OnlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_hAkG2LOppR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_fake_samples(g_model, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = g_model.predict(x_input)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((n_samples, 1))\n",
        "\treturn X, y"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZC36W5qQ4CE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\td_model.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(g_model)\n",
        "\t# add the discriminator\n",
        "\tmodel.add(d_model)\n",
        "\t# compile model\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp5OVszWkWHg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create and save a plot of generated images\n",
        "def save_plot(examples, epoch, n=7):\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\texamples = (examples + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(n * n):\n",
        "\t\t# define subplot\n",
        "\t\tplt.subplot(n, n, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tplt.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tplt.imshow(examples[i].reshape(48, 48))\n",
        "\t# save plot to file\n",
        "\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n",
        "\tplt.savefig(filename)\n",
        "\tplt.close()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smRROD_SOrTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotGeneratedImages(epoch, g_model, d_model, dataset, latent_dim, n_samples=150):\n",
        " # prepare real samples\n",
        "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
        "\t# evaluate discriminator on real examples\n",
        "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# evaluate discriminator on fake examples\n",
        "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# summarize discriminator performance\n",
        "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n",
        "\t# save plot\n",
        "\tsave_plot(x_fake, epoch)\n",
        "\t# save the generator model tile file\n",
        "\tfilename = 'generator_model_%03d.h5' % (epoch+1)\n",
        "\tg_model.save(filename)\n",
        "  "
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysGtksHEOthX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(g_model, d_model, gan_model, dataset, latent_dim, epochs=1, batchSize=128):\n",
        "\tbatchCount = int(dataset.shape[0] / batchSize)\n",
        "\thalf_batch = int(batchSize / 2)\n",
        "\tprint ('Epochs:', epochs)\n",
        "\tprint ('Batch size:', batchSize)\n",
        "\tprint ('Batches per epoch:', batchCount)\n",
        "\tss =1\n",
        "\tfor e in range(1, epochs+1):\n",
        "\t\tprint ('-'*15, 'Epoch %d' % e, '-'*15)        \n",
        "\t\tfor _ in range(batchCount):                        \n",
        "\t\t\tss = ss+1\n",
        "\t\t\t# Get a random set of input noise and images\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\tprint(X_real.shape)\n",
        "\t\t\tprint(y_real.shape)\n",
        "\t\t\t#update discriminator model weights\n",
        "\t\t\td_loss1, _ = d_model.train_on_batch(X_real, y_real)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# update discriminator model weights\n",
        "\t\t\td_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t\t# prepare points in latent space as input for the generator\n",
        "\t\t\tX_gan = generate_latent_points(latent_dim, batchSize)\n",
        "\t\t\t# create inverted labels for the fake samples\n",
        "\t\t\ty_gan = ones((batchSize, 1))\n",
        "\t\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\t\tprint('batch running-'+str(ss)+' '+ str(d_loss1) + ' ' +str(d_loss2) + ' '+str(g_loss))\n",
        "\t\tif e == 1 or e % 5 == 0:\n",
        "\t\t\tplotGeneratedImages(e, g_model, d_model, dataset, latent_dim)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIAUo_41OwMS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a5f62b58-0043-48a6-854f-8537556dfb0d"
      },
      "source": [
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# create the discriminator\n",
        "d_model = build_discriminator()\n",
        "# create the generator\n",
        "g_model = build_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(g_model, d_model)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 12, 12, 128)       147584    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 6, 6, 256)         295168    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9217      \n",
            "=================================================================\n",
            "Total params: 526,465\n",
            "Trainable params: 526,465\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 9216)              930816    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)   (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 12, 12, 128)       524416    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 24, 24, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)   (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTr (None, 48, 48, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)   (None, 48, 48, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 48, 48, 1)         1153      \n",
            "=================================================================\n",
            "Total params: 1,980,929\n",
            "Trainable params: 1,980,929\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KoHDOeYQDhB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train model\n",
        "train(g_model, d_model, gan_model, dataset, latent_dim, 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcO-UXPqS-2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}