{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhay43/ML_Code/blob/master/DL-MNIST_clothing_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv-SZwH4ZZJb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7dadf253-fd8d-4e03-f3a1-fb4f4816d89f"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.layers import Dense\n",
        "from keras import Sequential\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dropout "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmXbrJMwZgWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = keras.datasets.fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0dooYKrbvt2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "72f0bbe7-1c9b-40d3-87d5-fb69370554e2"
      },
      "source": [
        "(X_train, Y_train), (X_test, Y_test) =  data.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 4us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sazF4gbJcTFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train.reshape(len(X_train),784 )\n",
        "X_test = X_test.reshape(len(X_test),784 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00EA4SvjcYZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "# Normalizing the input to be within the range [0,1]\n",
        "X_train /= 255\n",
        "#intensity of each pixel is divided by 255, the maximum intensity value\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sCJgrUEdX6-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# One-hot representation of the labels.\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train, 10) \n",
        "Y_test = tf.keras.utils.to_categorical(Y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvgLaa46flRQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_0 = tf.keras.Sequential()\n",
        "hidden_layer = 10\n",
        "model_0.add(Dense(hidden_layer, input_shape=(784,),name='dense_layer_1', activation='relu' ))\n",
        "model_0.add(Dense(hidden_layer, name='dense_layer_2', activation='relu' ))\n",
        "model_0.add(Dense(hidden_layer, name='dense_layer_3', activation='softmax' ))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9_dj50kinA0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2721ebad-bfe9-46e7-f520-9f6436d333cd"
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L848Jxr_hrf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_0.compile(optimizer='SGD',  loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0nGYSlQiJHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8db2af8-5ec0-4677-8a3f-65b7ec7e0295"
      },
      "source": [
        "training = model_0.fit(X_train, Y_train, batch_size=64, epochs=70, validation_split=0.2)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3500 - accuracy: 0.8758 - val_loss: 0.4029 - val_accuracy: 0.8618\n",
            "Epoch 2/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8755 - val_loss: 0.4027 - val_accuracy: 0.8634\n",
            "Epoch 3/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3480 - accuracy: 0.8777 - val_loss: 0.4193 - val_accuracy: 0.8562\n",
            "Epoch 4/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3485 - accuracy: 0.8762 - val_loss: 0.4090 - val_accuracy: 0.8616\n",
            "Epoch 5/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3489 - accuracy: 0.8769 - val_loss: 0.4211 - val_accuracy: 0.8496\n",
            "Epoch 6/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3477 - accuracy: 0.8775 - val_loss: 0.4011 - val_accuracy: 0.8633\n",
            "Epoch 7/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8766 - val_loss: 0.4015 - val_accuracy: 0.8633\n",
            "Epoch 8/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3464 - accuracy: 0.8773 - val_loss: 0.4017 - val_accuracy: 0.8608\n",
            "Epoch 9/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3457 - accuracy: 0.8776 - val_loss: 0.4087 - val_accuracy: 0.8602\n",
            "Epoch 10/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8789 - val_loss: 0.4067 - val_accuracy: 0.8602\n",
            "Epoch 11/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3449 - accuracy: 0.8777 - val_loss: 0.4030 - val_accuracy: 0.8615\n",
            "Epoch 12/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8791 - val_loss: 0.4018 - val_accuracy: 0.8632\n",
            "Epoch 13/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3434 - accuracy: 0.8782 - val_loss: 0.4020 - val_accuracy: 0.8622\n",
            "Epoch 14/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3426 - accuracy: 0.8782 - val_loss: 0.4069 - val_accuracy: 0.8593\n",
            "Epoch 15/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3417 - accuracy: 0.8790 - val_loss: 0.3996 - val_accuracy: 0.8632\n",
            "Epoch 16/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3410 - accuracy: 0.8798 - val_loss: 0.4080 - val_accuracy: 0.8612\n",
            "Epoch 17/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3406 - accuracy: 0.8798 - val_loss: 0.4110 - val_accuracy: 0.8615\n",
            "Epoch 18/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8786 - val_loss: 0.4010 - val_accuracy: 0.8623\n",
            "Epoch 19/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3393 - accuracy: 0.8792 - val_loss: 0.4184 - val_accuracy: 0.8565\n",
            "Epoch 20/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3395 - accuracy: 0.8805 - val_loss: 0.4159 - val_accuracy: 0.8573\n",
            "Epoch 21/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3387 - accuracy: 0.8786 - val_loss: 0.4083 - val_accuracy: 0.8612\n",
            "Epoch 22/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3385 - accuracy: 0.8800 - val_loss: 0.4093 - val_accuracy: 0.8582\n",
            "Epoch 23/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3373 - accuracy: 0.8807 - val_loss: 0.4080 - val_accuracy: 0.8591\n",
            "Epoch 24/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8810 - val_loss: 0.4041 - val_accuracy: 0.8626\n",
            "Epoch 25/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3368 - accuracy: 0.8805 - val_loss: 0.4077 - val_accuracy: 0.8597\n",
            "Epoch 26/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3364 - accuracy: 0.8804 - val_loss: 0.3979 - val_accuracy: 0.8651\n",
            "Epoch 27/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3354 - accuracy: 0.8809 - val_loss: 0.4050 - val_accuracy: 0.8638\n",
            "Epoch 28/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3347 - accuracy: 0.8810 - val_loss: 0.4032 - val_accuracy: 0.8626\n",
            "Epoch 29/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.8816 - val_loss: 0.4082 - val_accuracy: 0.8600\n",
            "Epoch 30/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3338 - accuracy: 0.8820 - val_loss: 0.4047 - val_accuracy: 0.8633\n",
            "Epoch 31/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3336 - accuracy: 0.8810 - val_loss: 0.4029 - val_accuracy: 0.8646\n",
            "Epoch 32/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8823 - val_loss: 0.4112 - val_accuracy: 0.8559\n",
            "Epoch 33/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8813 - val_loss: 0.4030 - val_accuracy: 0.8632\n",
            "Epoch 34/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3318 - accuracy: 0.8825 - val_loss: 0.4046 - val_accuracy: 0.8613\n",
            "Epoch 35/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8823 - val_loss: 0.4075 - val_accuracy: 0.8618\n",
            "Epoch 36/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8831 - val_loss: 0.4116 - val_accuracy: 0.8616\n",
            "Epoch 37/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8827 - val_loss: 0.4009 - val_accuracy: 0.8638\n",
            "Epoch 38/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3297 - accuracy: 0.8836 - val_loss: 0.4042 - val_accuracy: 0.8606\n",
            "Epoch 39/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3299 - accuracy: 0.8816 - val_loss: 0.4002 - val_accuracy: 0.8641\n",
            "Epoch 40/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8827 - val_loss: 0.4093 - val_accuracy: 0.8612\n",
            "Epoch 41/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8837 - val_loss: 0.4023 - val_accuracy: 0.8617\n",
            "Epoch 42/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8836 - val_loss: 0.4063 - val_accuracy: 0.8637\n",
            "Epoch 43/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8827 - val_loss: 0.4046 - val_accuracy: 0.8621\n",
            "Epoch 44/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3275 - accuracy: 0.8840 - val_loss: 0.4254 - val_accuracy: 0.8556\n",
            "Epoch 45/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3265 - accuracy: 0.8842 - val_loss: 0.4061 - val_accuracy: 0.8631\n",
            "Epoch 46/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8846 - val_loss: 0.4050 - val_accuracy: 0.8604\n",
            "Epoch 47/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8842 - val_loss: 0.4095 - val_accuracy: 0.8613\n",
            "Epoch 48/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3255 - accuracy: 0.8844 - val_loss: 0.4068 - val_accuracy: 0.8627\n",
            "Epoch 49/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8840 - val_loss: 0.4149 - val_accuracy: 0.8592\n",
            "Epoch 50/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3244 - accuracy: 0.8845 - val_loss: 0.4072 - val_accuracy: 0.8626\n",
            "Epoch 51/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8838 - val_loss: 0.4224 - val_accuracy: 0.8560\n",
            "Epoch 52/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3237 - accuracy: 0.8845 - val_loss: 0.4029 - val_accuracy: 0.8637\n",
            "Epoch 53/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8850 - val_loss: 0.4100 - val_accuracy: 0.8597\n",
            "Epoch 54/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8842 - val_loss: 0.4132 - val_accuracy: 0.8588\n",
            "Epoch 55/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3230 - accuracy: 0.8846 - val_loss: 0.4082 - val_accuracy: 0.8632\n",
            "Epoch 56/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3223 - accuracy: 0.8851 - val_loss: 0.4141 - val_accuracy: 0.8610\n",
            "Epoch 57/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3224 - accuracy: 0.8851 - val_loss: 0.4295 - val_accuracy: 0.8496\n",
            "Epoch 58/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3216 - accuracy: 0.8857 - val_loss: 0.4092 - val_accuracy: 0.8627\n",
            "Epoch 59/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3206 - accuracy: 0.8847 - val_loss: 0.4061 - val_accuracy: 0.8616\n",
            "Epoch 60/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3213 - accuracy: 0.8854 - val_loss: 0.4124 - val_accuracy: 0.8602\n",
            "Epoch 61/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3205 - accuracy: 0.8865 - val_loss: 0.4178 - val_accuracy: 0.8600\n",
            "Epoch 62/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3209 - accuracy: 0.8853 - val_loss: 0.4079 - val_accuracy: 0.8621\n",
            "Epoch 63/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3199 - accuracy: 0.8855 - val_loss: 0.4153 - val_accuracy: 0.8602\n",
            "Epoch 64/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3187 - accuracy: 0.8873 - val_loss: 0.4072 - val_accuracy: 0.8629\n",
            "Epoch 65/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3192 - accuracy: 0.8864 - val_loss: 0.4172 - val_accuracy: 0.8637\n",
            "Epoch 66/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3198 - accuracy: 0.8862 - val_loss: 0.4278 - val_accuracy: 0.8574\n",
            "Epoch 67/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3193 - accuracy: 0.8863 - val_loss: 0.4264 - val_accuracy: 0.8553\n",
            "Epoch 68/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3188 - accuracy: 0.8868 - val_loss: 0.4065 - val_accuracy: 0.8627\n",
            "Epoch 69/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3184 - accuracy: 0.8867 - val_loss: 0.4210 - val_accuracy: 0.8583\n",
            "Epoch 70/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3180 - accuracy: 0.8869 - val_loss: 0.4238 - val_accuracy: 0.8584\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfshBawTicn5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7b29cca5-add2-4a19-b8b9-d7c92203efed"
      },
      "source": [
        "model_0.evaluate(X_test,Y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.8427\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.45214423537254333, 0.8427000045776367]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D98IlUMcl844",
        "colab_type": "text"
      },
      "source": [
        "**1) Do you get the same results if you run the Notebook multiple times without changing any parameters?** \n",
        "Answer - Yes it change the accuracy. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYm25yZwnU-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1 = tf.keras.Sequential()\n",
        "hidden_layer = 64\n",
        "model_1.add(Dense(hidden_layer, input_shape = (784,), name='layer_1', activation='relu'))\n",
        "model_1.add(Dense(hidden_layer, name='layer_2', activation='relu'))\n",
        "model_1.add(Dense(10, name='layer_3', activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J07KmzQp2_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_1.compile(optimizer='SGD',  loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dttqYkIUtb-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70f0f7db-5ed4-4be2-e85b-76f9ac8b7493"
      },
      "source": [
        "training = model_1.fit(X_train, Y_train, batch_size=64, epochs=70, validation_split=0.2)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.0275 - accuracy: 0.6715 - val_loss: 0.6731 - val_accuracy: 0.7693\n",
            "Epoch 2/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.6178 - accuracy: 0.7881 - val_loss: 0.5641 - val_accuracy: 0.8054\n",
            "Epoch 3/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5410 - accuracy: 0.8150 - val_loss: 0.5232 - val_accuracy: 0.8199\n",
            "Epoch 4/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.5026 - accuracy: 0.8279 - val_loss: 0.4884 - val_accuracy: 0.8297\n",
            "Epoch 5/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4791 - accuracy: 0.8345 - val_loss: 0.4848 - val_accuracy: 0.8275\n",
            "Epoch 6/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4606 - accuracy: 0.8407 - val_loss: 0.4655 - val_accuracy: 0.8346\n",
            "Epoch 7/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4470 - accuracy: 0.8451 - val_loss: 0.4446 - val_accuracy: 0.8450\n",
            "Epoch 8/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4346 - accuracy: 0.8490 - val_loss: 0.4363 - val_accuracy: 0.8467\n",
            "Epoch 9/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4243 - accuracy: 0.8520 - val_loss: 0.4394 - val_accuracy: 0.8499\n",
            "Epoch 10/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4158 - accuracy: 0.8560 - val_loss: 0.4541 - val_accuracy: 0.8330\n",
            "Epoch 11/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4079 - accuracy: 0.8579 - val_loss: 0.4209 - val_accuracy: 0.8491\n",
            "Epoch 12/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4005 - accuracy: 0.8616 - val_loss: 0.4088 - val_accuracy: 0.8566\n",
            "Epoch 13/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8628 - val_loss: 0.4070 - val_accuracy: 0.8592\n",
            "Epoch 14/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3887 - accuracy: 0.8656 - val_loss: 0.4114 - val_accuracy: 0.8557\n",
            "Epoch 15/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3831 - accuracy: 0.8672 - val_loss: 0.4177 - val_accuracy: 0.8509\n",
            "Epoch 16/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3792 - accuracy: 0.8680 - val_loss: 0.4319 - val_accuracy: 0.8468\n",
            "Epoch 17/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3738 - accuracy: 0.8698 - val_loss: 0.3896 - val_accuracy: 0.8647\n",
            "Epoch 18/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3693 - accuracy: 0.8714 - val_loss: 0.3955 - val_accuracy: 0.8618\n",
            "Epoch 19/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3650 - accuracy: 0.8739 - val_loss: 0.3923 - val_accuracy: 0.8604\n",
            "Epoch 20/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3606 - accuracy: 0.8755 - val_loss: 0.3823 - val_accuracy: 0.8689\n",
            "Epoch 21/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3564 - accuracy: 0.8761 - val_loss: 0.3816 - val_accuracy: 0.8670\n",
            "Epoch 22/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3531 - accuracy: 0.8779 - val_loss: 0.3879 - val_accuracy: 0.8660\n",
            "Epoch 23/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3499 - accuracy: 0.8786 - val_loss: 0.3906 - val_accuracy: 0.8663\n",
            "Epoch 24/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3451 - accuracy: 0.8795 - val_loss: 0.3831 - val_accuracy: 0.8691\n",
            "Epoch 25/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3422 - accuracy: 0.8809 - val_loss: 0.3796 - val_accuracy: 0.8665\n",
            "Epoch 26/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3387 - accuracy: 0.8820 - val_loss: 0.3654 - val_accuracy: 0.8721\n",
            "Epoch 27/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3351 - accuracy: 0.8824 - val_loss: 0.3897 - val_accuracy: 0.8633\n",
            "Epoch 28/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3321 - accuracy: 0.8840 - val_loss: 0.3698 - val_accuracy: 0.8698\n",
            "Epoch 29/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8854 - val_loss: 0.3621 - val_accuracy: 0.8731\n",
            "Epoch 30/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3258 - accuracy: 0.8861 - val_loss: 0.3621 - val_accuracy: 0.8732\n",
            "Epoch 31/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3236 - accuracy: 0.8855 - val_loss: 0.3593 - val_accuracy: 0.8733\n",
            "Epoch 32/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3198 - accuracy: 0.8867 - val_loss: 0.3602 - val_accuracy: 0.8740\n",
            "Epoch 33/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3177 - accuracy: 0.8879 - val_loss: 0.3575 - val_accuracy: 0.8730\n",
            "Epoch 34/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3145 - accuracy: 0.8885 - val_loss: 0.3611 - val_accuracy: 0.8739\n",
            "Epoch 35/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3115 - accuracy: 0.8904 - val_loss: 0.3547 - val_accuracy: 0.8763\n",
            "Epoch 36/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3088 - accuracy: 0.8911 - val_loss: 0.3563 - val_accuracy: 0.8735\n",
            "Epoch 37/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3066 - accuracy: 0.8921 - val_loss: 0.3491 - val_accuracy: 0.8777\n",
            "Epoch 38/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3038 - accuracy: 0.8923 - val_loss: 0.3585 - val_accuracy: 0.8741\n",
            "Epoch 39/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3023 - accuracy: 0.8928 - val_loss: 0.3505 - val_accuracy: 0.8744\n",
            "Epoch 40/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2988 - accuracy: 0.8940 - val_loss: 0.3537 - val_accuracy: 0.8737\n",
            "Epoch 41/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2961 - accuracy: 0.8949 - val_loss: 0.3558 - val_accuracy: 0.8757\n",
            "Epoch 42/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2944 - accuracy: 0.8952 - val_loss: 0.3512 - val_accuracy: 0.8777\n",
            "Epoch 43/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2925 - accuracy: 0.8941 - val_loss: 0.3541 - val_accuracy: 0.8764\n",
            "Epoch 44/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2893 - accuracy: 0.8967 - val_loss: 0.3576 - val_accuracy: 0.8730\n",
            "Epoch 45/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2870 - accuracy: 0.8980 - val_loss: 0.3448 - val_accuracy: 0.8795\n",
            "Epoch 46/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2863 - accuracy: 0.8977 - val_loss: 0.3499 - val_accuracy: 0.8768\n",
            "Epoch 47/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2840 - accuracy: 0.8985 - val_loss: 0.3393 - val_accuracy: 0.8817\n",
            "Epoch 48/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2820 - accuracy: 0.8987 - val_loss: 0.3431 - val_accuracy: 0.8801\n",
            "Epoch 49/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2796 - accuracy: 0.9010 - val_loss: 0.3455 - val_accuracy: 0.8792\n",
            "Epoch 50/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2781 - accuracy: 0.9009 - val_loss: 0.3384 - val_accuracy: 0.8824\n",
            "Epoch 51/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2758 - accuracy: 0.9006 - val_loss: 0.3473 - val_accuracy: 0.8772\n",
            "Epoch 52/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2732 - accuracy: 0.9023 - val_loss: 0.3504 - val_accuracy: 0.8790\n",
            "Epoch 53/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2730 - accuracy: 0.9023 - val_loss: 0.3483 - val_accuracy: 0.8759\n",
            "Epoch 54/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2711 - accuracy: 0.9027 - val_loss: 0.3423 - val_accuracy: 0.8792\n",
            "Epoch 55/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2690 - accuracy: 0.9038 - val_loss: 0.3380 - val_accuracy: 0.8819\n",
            "Epoch 56/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2676 - accuracy: 0.9032 - val_loss: 0.3342 - val_accuracy: 0.8836\n",
            "Epoch 57/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2646 - accuracy: 0.9053 - val_loss: 0.3439 - val_accuracy: 0.8792\n",
            "Epoch 58/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2628 - accuracy: 0.9057 - val_loss: 0.3454 - val_accuracy: 0.8808\n",
            "Epoch 59/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2620 - accuracy: 0.9063 - val_loss: 0.3365 - val_accuracy: 0.8825\n",
            "Epoch 60/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2609 - accuracy: 0.9067 - val_loss: 0.3497 - val_accuracy: 0.8788\n",
            "Epoch 61/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2590 - accuracy: 0.9065 - val_loss: 0.3512 - val_accuracy: 0.8788\n",
            "Epoch 62/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2568 - accuracy: 0.9072 - val_loss: 0.3356 - val_accuracy: 0.8837\n",
            "Epoch 63/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2560 - accuracy: 0.9083 - val_loss: 0.3484 - val_accuracy: 0.8785\n",
            "Epoch 64/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2541 - accuracy: 0.9088 - val_loss: 0.3414 - val_accuracy: 0.8825\n",
            "Epoch 65/70\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2528 - accuracy: 0.9099 - val_loss: 0.3556 - val_accuracy: 0.8800\n",
            "Epoch 66/70\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2514 - accuracy: 0.9107 - val_loss: 0.3283 - val_accuracy: 0.8874\n",
            "Epoch 67/70\n",
            "750/750 [==============================] - 3s 4ms/step - loss: 0.2497 - accuracy: 0.9096 - val_loss: 0.3482 - val_accuracy: 0.8825\n",
            "Epoch 68/70\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.2488 - accuracy: 0.9103 - val_loss: 0.3381 - val_accuracy: 0.8833\n",
            "Epoch 69/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2467 - accuracy: 0.9110 - val_loss: 0.3317 - val_accuracy: 0.8849\n",
            "Epoch 70/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2450 - accuracy: 0.9126 - val_loss: 0.3379 - val_accuracy: 0.8850\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADSTKOX_tgCo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "75b3d66b-3ef9-479e-b262-9543abf3ee58"
      },
      "source": [
        "model_1.evaluate(X_test, Y_test)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3640 - accuracy: 0.8732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.36401376128196716, 0.873199999332428]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIpaYmViuOpw",
        "colab_type": "text"
      },
      "source": [
        "**2) What is the effect of adding more neurons to each Conv2D layer?** Answer - It seems like it incress the accuracy if adding more neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XlFDWKrulMJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_2 = tf.keras.Sequential()\n",
        "hidden_layer = 512\n",
        "model_2.add(Dense(hidden_layer, input_shape = (784,), name='layer_1', activation='relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "model_2.add(Dense(hidden_layer, name='layer_2', activation='relu'))\n",
        "model_2.add(Dropout(0.2))\n",
        "model_2.add(Dense(10, name='layer_3', activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naPdnNMkwHXb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02b110f9-0876-4bb9-acb3-b812e248d3d2"
      },
      "source": [
        "model_2.compile(optimizer='SGD',  loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "training = model_2.fit(X_train, Y_train, batch_size=64, epochs=70, validation_split=0.2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.9734 - accuracy: 0.6844 - val_loss: 0.6289 - val_accuracy: 0.7842\n",
            "Epoch 2/70\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.6277 - accuracy: 0.7854 - val_loss: 0.5279 - val_accuracy: 0.8220\n",
            "Epoch 3/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.5558 - accuracy: 0.8090 - val_loss: 0.4937 - val_accuracy: 0.8282\n",
            "Epoch 4/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.5131 - accuracy: 0.8216 - val_loss: 0.4678 - val_accuracy: 0.8365\n",
            "Epoch 5/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4880 - accuracy: 0.8303 - val_loss: 0.4481 - val_accuracy: 0.8418\n",
            "Epoch 6/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4674 - accuracy: 0.8361 - val_loss: 0.4363 - val_accuracy: 0.8440\n",
            "Epoch 7/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4505 - accuracy: 0.8429 - val_loss: 0.4215 - val_accuracy: 0.8498\n",
            "Epoch 8/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4365 - accuracy: 0.8484 - val_loss: 0.4148 - val_accuracy: 0.8523\n",
            "Epoch 9/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4238 - accuracy: 0.8497 - val_loss: 0.4033 - val_accuracy: 0.8558\n",
            "Epoch 10/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4131 - accuracy: 0.8543 - val_loss: 0.3934 - val_accuracy: 0.8614\n",
            "Epoch 11/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.4051 - accuracy: 0.8560 - val_loss: 0.3878 - val_accuracy: 0.8628\n",
            "Epoch 12/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3964 - accuracy: 0.8605 - val_loss: 0.3812 - val_accuracy: 0.8641\n",
            "Epoch 13/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3886 - accuracy: 0.8625 - val_loss: 0.3782 - val_accuracy: 0.8649\n",
            "Epoch 14/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3796 - accuracy: 0.8645 - val_loss: 0.3730 - val_accuracy: 0.8674\n",
            "Epoch 15/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3725 - accuracy: 0.8677 - val_loss: 0.3684 - val_accuracy: 0.8698\n",
            "Epoch 16/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3672 - accuracy: 0.8699 - val_loss: 0.3667 - val_accuracy: 0.8702\n",
            "Epoch 17/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3627 - accuracy: 0.8706 - val_loss: 0.3610 - val_accuracy: 0.8734\n",
            "Epoch 18/70\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3564 - accuracy: 0.8738 - val_loss: 0.3553 - val_accuracy: 0.8758\n",
            "Epoch 19/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3516 - accuracy: 0.8755 - val_loss: 0.3519 - val_accuracy: 0.8762\n",
            "Epoch 20/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3447 - accuracy: 0.8770 - val_loss: 0.3551 - val_accuracy: 0.8715\n",
            "Epoch 21/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3409 - accuracy: 0.8783 - val_loss: 0.3487 - val_accuracy: 0.8771\n",
            "Epoch 22/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3377 - accuracy: 0.8788 - val_loss: 0.3446 - val_accuracy: 0.8748\n",
            "Epoch 23/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3330 - accuracy: 0.8811 - val_loss: 0.3416 - val_accuracy: 0.8784\n",
            "Epoch 24/70\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3303 - accuracy: 0.8823 - val_loss: 0.3394 - val_accuracy: 0.8812\n",
            "Epoch 25/70\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3252 - accuracy: 0.8844 - val_loss: 0.3367 - val_accuracy: 0.8802\n",
            "Epoch 26/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3208 - accuracy: 0.8857 - val_loss: 0.3363 - val_accuracy: 0.8802\n",
            "Epoch 27/70\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.3186 - accuracy: 0.8849 - val_loss: 0.3371 - val_accuracy: 0.8786\n",
            "Epoch 28/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3149 - accuracy: 0.8870 - val_loss: 0.3315 - val_accuracy: 0.8827\n",
            "Epoch 29/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3110 - accuracy: 0.8878 - val_loss: 0.3291 - val_accuracy: 0.8848\n",
            "Epoch 30/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3082 - accuracy: 0.8892 - val_loss: 0.3290 - val_accuracy: 0.8827\n",
            "Epoch 31/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3054 - accuracy: 0.8907 - val_loss: 0.3235 - val_accuracy: 0.8859\n",
            "Epoch 32/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.3022 - accuracy: 0.8920 - val_loss: 0.3266 - val_accuracy: 0.8842\n",
            "Epoch 33/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2986 - accuracy: 0.8931 - val_loss: 0.3222 - val_accuracy: 0.8870\n",
            "Epoch 34/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2957 - accuracy: 0.8934 - val_loss: 0.3202 - val_accuracy: 0.8867\n",
            "Epoch 35/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2937 - accuracy: 0.8941 - val_loss: 0.3177 - val_accuracy: 0.8882\n",
            "Epoch 36/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2898 - accuracy: 0.8964 - val_loss: 0.3166 - val_accuracy: 0.8868\n",
            "Epoch 37/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2878 - accuracy: 0.8963 - val_loss: 0.3193 - val_accuracy: 0.8846\n",
            "Epoch 38/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2851 - accuracy: 0.8982 - val_loss: 0.3157 - val_accuracy: 0.8871\n",
            "Epoch 39/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2811 - accuracy: 0.8994 - val_loss: 0.3144 - val_accuracy: 0.8872\n",
            "Epoch 40/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2807 - accuracy: 0.8993 - val_loss: 0.3112 - val_accuracy: 0.8888\n",
            "Epoch 41/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2780 - accuracy: 0.8997 - val_loss: 0.3163 - val_accuracy: 0.8869\n",
            "Epoch 42/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2735 - accuracy: 0.9009 - val_loss: 0.3126 - val_accuracy: 0.8882\n",
            "Epoch 43/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2713 - accuracy: 0.9014 - val_loss: 0.3099 - val_accuracy: 0.8893\n",
            "Epoch 44/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2706 - accuracy: 0.9023 - val_loss: 0.3107 - val_accuracy: 0.8907\n",
            "Epoch 45/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2663 - accuracy: 0.9042 - val_loss: 0.3104 - val_accuracy: 0.8890\n",
            "Epoch 46/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2666 - accuracy: 0.9038 - val_loss: 0.3079 - val_accuracy: 0.8892\n",
            "Epoch 47/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2624 - accuracy: 0.9052 - val_loss: 0.3040 - val_accuracy: 0.8918\n",
            "Epoch 48/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2603 - accuracy: 0.9056 - val_loss: 0.3072 - val_accuracy: 0.8882\n",
            "Epoch 49/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2588 - accuracy: 0.9060 - val_loss: 0.3057 - val_accuracy: 0.8893\n",
            "Epoch 50/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2571 - accuracy: 0.9075 - val_loss: 0.3049 - val_accuracy: 0.8891\n",
            "Epoch 51/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2546 - accuracy: 0.9077 - val_loss: 0.3069 - val_accuracy: 0.8882\n",
            "Epoch 52/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2525 - accuracy: 0.9106 - val_loss: 0.3046 - val_accuracy: 0.8907\n",
            "Epoch 53/70\n",
            "750/750 [==============================] - 7s 9ms/step - loss: 0.2505 - accuracy: 0.9107 - val_loss: 0.3036 - val_accuracy: 0.8890\n",
            "Epoch 54/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2465 - accuracy: 0.9110 - val_loss: 0.3011 - val_accuracy: 0.8927\n",
            "Epoch 55/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2449 - accuracy: 0.9104 - val_loss: 0.2997 - val_accuracy: 0.8932\n",
            "Epoch 56/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2452 - accuracy: 0.9122 - val_loss: 0.2977 - val_accuracy: 0.8934\n",
            "Epoch 57/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2411 - accuracy: 0.9135 - val_loss: 0.2994 - val_accuracy: 0.8925\n",
            "Epoch 58/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2404 - accuracy: 0.9124 - val_loss: 0.2987 - val_accuracy: 0.8932\n",
            "Epoch 59/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2386 - accuracy: 0.9144 - val_loss: 0.2949 - val_accuracy: 0.8947\n",
            "Epoch 60/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2359 - accuracy: 0.9148 - val_loss: 0.2958 - val_accuracy: 0.8922\n",
            "Epoch 61/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2345 - accuracy: 0.9148 - val_loss: 0.2971 - val_accuracy: 0.8941\n",
            "Epoch 62/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2328 - accuracy: 0.9154 - val_loss: 0.2984 - val_accuracy: 0.8918\n",
            "Epoch 63/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2284 - accuracy: 0.9186 - val_loss: 0.3003 - val_accuracy: 0.8929\n",
            "Epoch 64/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2303 - accuracy: 0.9154 - val_loss: 0.2999 - val_accuracy: 0.8923\n",
            "Epoch 65/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2275 - accuracy: 0.9177 - val_loss: 0.2940 - val_accuracy: 0.8950\n",
            "Epoch 66/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2241 - accuracy: 0.9187 - val_loss: 0.2987 - val_accuracy: 0.8917\n",
            "Epoch 67/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2231 - accuracy: 0.9191 - val_loss: 0.2951 - val_accuracy: 0.8938\n",
            "Epoch 68/70\n",
            "750/750 [==============================] - 8s 10ms/step - loss: 0.2202 - accuracy: 0.9217 - val_loss: 0.2995 - val_accuracy: 0.8918\n",
            "Epoch 69/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2204 - accuracy: 0.9208 - val_loss: 0.3001 - val_accuracy: 0.8927\n",
            "Epoch 70/70\n",
            "750/750 [==============================] - 7s 10ms/step - loss: 0.2171 - accuracy: 0.9211 - val_loss: 0.2930 - val_accuracy: 0.8953\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE8IriUmwg_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5a771842-4e4e-4bc8-8d23-6421d5a0cfca"
      },
      "source": [
        "model_2.evaluate(X_test, Y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3169 - accuracy: 0.8886\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.31690990924835205, 0.8885999917984009]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrCM4GfUyNrf",
        "colab_type": "text"
      },
      "source": [
        "**3) What happens if we manipulate the value of Dropout?** Answer- It incress the accuracy and reduce the overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ID8-9-qKxLZz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4211226e-7bd8-4b65-aa04-2770eacad03d"
      },
      "source": [
        "model_3 = tf.keras.Sequential()\n",
        "hidden_layer = 32\n",
        "model_3.add(Dense(hidden_layer, input_shape = (784,), name='layer_1', activation='relu'))\n",
        "model_3.add(Dense(hidden_layer, name='layer_2', activation='relu'))\n",
        "model_3.add(Dense(hidden_layer, name='layer_3', activation='relu'))\n",
        "model_3.add(Dense(hidden_layer, name='layer_4', activation='relu'))\n",
        "model_3.add(Dense(10, name='layer_5', activation='softmax'))\n",
        "\n",
        "model_3.compile(optimizer='SGD',  loss='categorical_crossentropy',metrics=['accuracy'] )\n",
        "training = model_3.fit(X_train, Y_train, batch_size=64, epochs=70, validation_split=0.2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 1.2558 - accuracy: 0.5606 - val_loss: 0.7103 - val_accuracy: 0.7448\n",
            "Epoch 2/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.6478 - accuracy: 0.7694 - val_loss: 0.6474 - val_accuracy: 0.7706\n",
            "Epoch 3/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.5606 - accuracy: 0.8011 - val_loss: 0.5486 - val_accuracy: 0.7998\n",
            "Epoch 4/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.5129 - accuracy: 0.8191 - val_loss: 0.5058 - val_accuracy: 0.8217\n",
            "Epoch 5/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4833 - accuracy: 0.8298 - val_loss: 0.4856 - val_accuracy: 0.8313\n",
            "Epoch 6/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4575 - accuracy: 0.8388 - val_loss: 0.4548 - val_accuracy: 0.8378\n",
            "Epoch 7/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.4407 - accuracy: 0.8450 - val_loss: 0.4412 - val_accuracy: 0.8449\n",
            "Epoch 8/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4282 - accuracy: 0.8484 - val_loss: 0.4528 - val_accuracy: 0.8392\n",
            "Epoch 9/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4179 - accuracy: 0.8519 - val_loss: 0.4181 - val_accuracy: 0.8538\n",
            "Epoch 10/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.4073 - accuracy: 0.8573 - val_loss: 0.4150 - val_accuracy: 0.8527\n",
            "Epoch 11/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3997 - accuracy: 0.8588 - val_loss: 0.4068 - val_accuracy: 0.8556\n",
            "Epoch 12/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3915 - accuracy: 0.8605 - val_loss: 0.4045 - val_accuracy: 0.8572\n",
            "Epoch 13/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3851 - accuracy: 0.8638 - val_loss: 0.4095 - val_accuracy: 0.8565\n",
            "Epoch 14/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3784 - accuracy: 0.8655 - val_loss: 0.3956 - val_accuracy: 0.8600\n",
            "Epoch 15/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3724 - accuracy: 0.8671 - val_loss: 0.3834 - val_accuracy: 0.8620\n",
            "Epoch 16/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3655 - accuracy: 0.8694 - val_loss: 0.3998 - val_accuracy: 0.8557\n",
            "Epoch 17/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3615 - accuracy: 0.8708 - val_loss: 0.3825 - val_accuracy: 0.8636\n",
            "Epoch 18/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3562 - accuracy: 0.8731 - val_loss: 0.3844 - val_accuracy: 0.8620\n",
            "Epoch 19/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8748 - val_loss: 0.3766 - val_accuracy: 0.8637\n",
            "Epoch 20/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3472 - accuracy: 0.8750 - val_loss: 0.3776 - val_accuracy: 0.8621\n",
            "Epoch 21/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8764 - val_loss: 0.3693 - val_accuracy: 0.8696\n",
            "Epoch 22/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3390 - accuracy: 0.8783 - val_loss: 0.3643 - val_accuracy: 0.8722\n",
            "Epoch 23/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3342 - accuracy: 0.8786 - val_loss: 0.3825 - val_accuracy: 0.8632\n",
            "Epoch 24/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3307 - accuracy: 0.8816 - val_loss: 0.3789 - val_accuracy: 0.8644\n",
            "Epoch 25/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3279 - accuracy: 0.8815 - val_loss: 0.3639 - val_accuracy: 0.8698\n",
            "Epoch 26/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8829 - val_loss: 0.3679 - val_accuracy: 0.8678\n",
            "Epoch 27/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3199 - accuracy: 0.8851 - val_loss: 0.3650 - val_accuracy: 0.8682\n",
            "Epoch 28/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.3177 - accuracy: 0.8853 - val_loss: 0.3591 - val_accuracy: 0.8716\n",
            "Epoch 29/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3135 - accuracy: 0.8861 - val_loss: 0.3630 - val_accuracy: 0.8686\n",
            "Epoch 30/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3119 - accuracy: 0.8865 - val_loss: 0.3585 - val_accuracy: 0.8736\n",
            "Epoch 31/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3084 - accuracy: 0.8873 - val_loss: 0.3583 - val_accuracy: 0.8729\n",
            "Epoch 32/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3051 - accuracy: 0.8902 - val_loss: 0.3782 - val_accuracy: 0.8603\n",
            "Epoch 33/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.3018 - accuracy: 0.8905 - val_loss: 0.3555 - val_accuracy: 0.8732\n",
            "Epoch 34/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2999 - accuracy: 0.8906 - val_loss: 0.3702 - val_accuracy: 0.8685\n",
            "Epoch 35/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2965 - accuracy: 0.8920 - val_loss: 0.3510 - val_accuracy: 0.8781\n",
            "Epoch 36/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2940 - accuracy: 0.8929 - val_loss: 0.3498 - val_accuracy: 0.8758\n",
            "Epoch 37/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2940 - accuracy: 0.8925 - val_loss: 0.3618 - val_accuracy: 0.8717\n",
            "Epoch 38/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2885 - accuracy: 0.8947 - val_loss: 0.3456 - val_accuracy: 0.8759\n",
            "Epoch 39/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2878 - accuracy: 0.8948 - val_loss: 0.3458 - val_accuracy: 0.8771\n",
            "Epoch 40/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8964 - val_loss: 0.3545 - val_accuracy: 0.8720\n",
            "Epoch 41/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2827 - accuracy: 0.8962 - val_loss: 0.3510 - val_accuracy: 0.8755\n",
            "Epoch 42/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2824 - accuracy: 0.8966 - val_loss: 0.3483 - val_accuracy: 0.8758\n",
            "Epoch 43/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2792 - accuracy: 0.8979 - val_loss: 0.3555 - val_accuracy: 0.8770\n",
            "Epoch 44/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2771 - accuracy: 0.8968 - val_loss: 0.3488 - val_accuracy: 0.8783\n",
            "Epoch 45/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2747 - accuracy: 0.9007 - val_loss: 0.3497 - val_accuracy: 0.8772\n",
            "Epoch 46/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2727 - accuracy: 0.8998 - val_loss: 0.3576 - val_accuracy: 0.8740\n",
            "Epoch 47/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2721 - accuracy: 0.9010 - val_loss: 0.3432 - val_accuracy: 0.8795\n",
            "Epoch 48/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2697 - accuracy: 0.9011 - val_loss: 0.3493 - val_accuracy: 0.8766\n",
            "Epoch 49/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2682 - accuracy: 0.9005 - val_loss: 0.3469 - val_accuracy: 0.8773\n",
            "Epoch 50/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2659 - accuracy: 0.9032 - val_loss: 0.3430 - val_accuracy: 0.8792\n",
            "Epoch 51/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2641 - accuracy: 0.9031 - val_loss: 0.3554 - val_accuracy: 0.8741\n",
            "Epoch 52/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2625 - accuracy: 0.9042 - val_loss: 0.3444 - val_accuracy: 0.8778\n",
            "Epoch 53/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2600 - accuracy: 0.9044 - val_loss: 0.3635 - val_accuracy: 0.8706\n",
            "Epoch 54/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2581 - accuracy: 0.9050 - val_loss: 0.3637 - val_accuracy: 0.8741\n",
            "Epoch 55/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2582 - accuracy: 0.9056 - val_loss: 0.3498 - val_accuracy: 0.8773\n",
            "Epoch 56/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2574 - accuracy: 0.9056 - val_loss: 0.3548 - val_accuracy: 0.8778\n",
            "Epoch 57/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2545 - accuracy: 0.9054 - val_loss: 0.3574 - val_accuracy: 0.8738\n",
            "Epoch 58/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2530 - accuracy: 0.9064 - val_loss: 0.3544 - val_accuracy: 0.8767\n",
            "Epoch 59/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2512 - accuracy: 0.9070 - val_loss: 0.3660 - val_accuracy: 0.8752\n",
            "Epoch 60/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2487 - accuracy: 0.9079 - val_loss: 0.3473 - val_accuracy: 0.8772\n",
            "Epoch 61/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2495 - accuracy: 0.9086 - val_loss: 0.3760 - val_accuracy: 0.8738\n",
            "Epoch 62/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2463 - accuracy: 0.9090 - val_loss: 0.3485 - val_accuracy: 0.8808\n",
            "Epoch 63/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2462 - accuracy: 0.9100 - val_loss: 0.3628 - val_accuracy: 0.8723\n",
            "Epoch 64/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2444 - accuracy: 0.9095 - val_loss: 0.3513 - val_accuracy: 0.8782\n",
            "Epoch 65/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.9104 - val_loss: 0.3543 - val_accuracy: 0.8781\n",
            "Epoch 66/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2400 - accuracy: 0.9119 - val_loss: 0.3663 - val_accuracy: 0.8733\n",
            "Epoch 67/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2403 - accuracy: 0.9120 - val_loss: 0.3838 - val_accuracy: 0.8690\n",
            "Epoch 68/70\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.2382 - accuracy: 0.9125 - val_loss: 0.3480 - val_accuracy: 0.8788\n",
            "Epoch 69/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2370 - accuracy: 0.9136 - val_loss: 0.3570 - val_accuracy: 0.8760\n",
            "Epoch 70/70\n",
            "750/750 [==============================] - 1s 2ms/step - loss: 0.2366 - accuracy: 0.9135 - val_loss: 0.3591 - val_accuracy: 0.8761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RaQXIeAr0OYy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f4a6b3d4-ea42-4179-897f-f4422239d6e3"
      },
      "source": [
        "model_3.evaluate(X_test,Y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3851 - accuracy: 0.8674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.38507112860679626, 0.8673999905586243]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qan516EzBaw",
        "colab_type": "text"
      },
      "source": [
        "**4) What is the effect of adding more hiddenlayers to the network?** Answer - It does not add any value in this case if I added more layer in the model. But generally we can improves the performance "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjgzTh1K2exs",
        "colab_type": "text"
      },
      "source": [
        "**5) Does manipulating the learning rate affect the model? Justify your answer.** Answer - Learning rate is used to control the greedy/ non-greedy strategy.It can be positively effect or also it can negatively effect the model. If large learning rate is given then a small change in the value may effect the performance.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9DpZIfZ36U8",
        "colab_type": "text"
      },
      "source": [
        "**6) What is the best parameter configuration for this project?** Answer - model_2 is having 88.86% accuracy. So the parameters that is used there is the most optimum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTE-6x4yzF4o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}